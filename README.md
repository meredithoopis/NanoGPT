# NanoGPT
First-ever deep learning project 

This project draws inspiration from Andrej Karpathy's Youtube series on deep learning - NLP. The NanoGPT relies on the transformer model and multi-head attention algorithm to generate the next character given a limited context length. Initially, the model used the Shakespeare dataset with a view to developing English-like words used in the 18th century. After redeveloping in the future, the dataset will be changed to contain modern English words and the goal of the model will be to generate English words given the context 

Mr.Karpathy's videos get me into the world of deep learning and this project is mostly a replica - an imitation with at least some modifications from a person yearning to comprehend NLP in deep learning

Inspiration: https://arxiv.org/pdf/1706.03762.pdf 

FOR TIME-SAVING PURPOSES, IN THE COLAB FILE, REFER TO THE LAST CELL TO RUN THE MODEL

